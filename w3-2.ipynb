{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import matplotlib\n",
    "# matplotlib.use('TkAgg')\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "path = '/Users/jiayun/PycharmProjects/untitled/untitled/' \\\n",
    "       'untitled/rbot Project/ my code/machine learning/w' \\\n",
    "       'eek3 logistic regression/ex2data2.txt'\n",
    "\n",
    "data = pd.read_csv(path, header = None, names=['test 1', 'test 2', 'Accepted'])\n",
    "data.head()\n",
    "\n",
    "positive = data[data['Accepted'].isin([1])]\n",
    "negative = data[data['Accepted'].isin([0])]\n",
    "\n",
    "fig,ax = plt.subplots(figsize = (12,8))\n",
    "ax.scatter(positive['test 1'], positive['test 2'],s=50, c ='b',marker='o',label='Accepted')\n",
    "ax.scatter(negative['test 1'], negative['test 2'],s=50, c ='r',marker='*',label='Not Accepted')\n",
    "ax.legend()\n",
    "ax.set_xlabel('Test 1 Score')\n",
    "ax.set_ylabel('Test 2 Score')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "'''1.polynomial feature'''\n",
    "################################################################################\n",
    "########---------------------1.构建polynomial feature---------------------------########\n",
    "################################################################################\n",
    "\n",
    "degree = 5\n",
    "x1 = data['test 1']\n",
    "x2 = data['test 2']\n",
    "data.insert(3, 'ones', 1)\n",
    "\n",
    "for i in range(1,degree):\n",
    "    for j in range(0,i):\n",
    "        data['F' + str(i) + str(j)] = np.power(x1, i-j) * np.power(x2, j) # 这行是给data 一个新列，列名是'F i j '每次计算一次，给一个新的列\n",
    "\n",
    "'''   下面是对上面一段代码的解读：哈哈哈\n",
    "     i 是range（1，5）， 就是 1，2，3，4；\n",
    "        j是每次（0，i），就是从 0 到 i-1；\n",
    "            i-j 就是每次\n",
    "\n",
    "for p in range(1,5):\n",
    "    print(p)\n",
    "    \n",
    "for i in range(1,degree):\n",
    "    for j in range(0,i):\n",
    "        print(i,j,i-j)\n",
    "\n",
    "'''\n",
    "data.drop('test 1', axis=1, inplace = True)         # 把test1 这列删除\n",
    "data.drop('test 2', axis=1, inplace = True)         # 把test2 这列删除\n",
    "data.head()\n",
    "\n",
    "################################################################################\n",
    "########--------------------polynomial feature end------------------------########\n",
    "################################################################################\n",
    "\n",
    "\n",
    "\n",
    "'''2.正则化代价函数'''\n",
    "################################################################################\n",
    "########--------------------regularized cost（正则化代价函数） ------------------------########\n",
    "################################################################################\n",
    "def sigmoid(z):\n",
    "    result = 1 / (1+ np.exp(-z))    # 这地方也可以用 np.exp(-z) 一样的\n",
    "    return  result\n",
    "\n",
    "def costFunc(theta, x, y, lamda): # lamda 是 learning rate\n",
    "\n",
    "    theta = np.matrix(theta)\n",
    "    x = np.matrix(x)\n",
    "    y = np.matrix(y)\n",
    "    z = x * (theta.T)\n",
    "\n",
    "    first_term = np.multiply(-y, np.log(sigmoid(z)))\n",
    "    second_term = np.multiply((1-y), np.log(1-sigmoid(z)))\n",
    "    reg = lamda * (np.power(theta[:,1:theta.shape[1]],2))  # np.square(theta[:,1:theta.shape[1]])\n",
    "\n",
    "    Jval = (np.sum(first_term - second_term)) / (len(x))  + ((np.sum(reg)) / (2*len(x)))\n",
    "\n",
    "    return Jval\n",
    "\n",
    "################################################################################\n",
    "########--------------------regularized cost（正则化代价函数） ------------------------########\n",
    "################################################################################\n",
    "\n",
    "'''3.gradient function'''\n",
    "##############################################################################\n",
    "########--------------------gradient function------------------------########\n",
    "################################################################################\n",
    "\n",
    "def gradient(theta, x, y, lamda):\n",
    "    theta = np.matrix(theta)\n",
    "    x = np.matrix(x)\n",
    "    y = np.matrix(y)\n",
    "    z = x * theta.T\n",
    "\n",
    "    parameter = int(theta.ravel().shape[1])\n",
    "    m = x.shape[0]\n",
    "\n",
    "    grad = np.zeros(parameter)\n",
    "    error = sigmoid(z) - y\n",
    "\n",
    "    for j in range(parameter):\n",
    "\n",
    "        term = np.multiply(error, x[:,j])\n",
    "\n",
    "        if j == 0:\n",
    "            grad[j] = np.sum(term) / m\n",
    "\n",
    "        else:\n",
    "            grad[j] = lamda * np.sum(term) / m\n",
    "\n",
    "    return grad\n",
    "\n",
    "##############################################################################\n",
    "########--------------------gradient function end------------------------########\n",
    "################################################################################\n",
    "\n",
    "'''5。计算部分，调用上面的函数'''\n",
    "##############################################################################\n",
    "########--------------------计算------------------------########\n",
    "##############################################################################\n",
    "\n",
    "cols = data.shape[1]\n",
    "x = data.iloc[:,1:cols]\n",
    "y = data.iloc[:,0:1]\n",
    "\n",
    "x = np.array(x)\n",
    "y = np.array(y)\n",
    "theta = np.zeros(x.shape[1])\n",
    "\n",
    "lamda = 1\n",
    "costFunc(theta,x,y,lamda)  # test costFunction, make sure they can work\n",
    "gradient(theta,x,y,lamda)   # test gradient , make sure they can work\n",
    "\n",
    "\n",
    "import scipy.optimize as opt\n",
    "#  这是上一次饮用这个 result = opt.fmin_tnc(func=costFunction, x0=theta, fprime=gradient, args=(X,y))\n",
    "result = opt.fmin_tnc(func=costFunc, x0 = theta, fprime = gradient, args = (x,y,lamda))\n",
    "\n",
    "theta_final = np.matrix(result[0])\n",
    "''' prediction function'''\n",
    "def predict(theta, x):\n",
    "    # theta = np.matrix(theta)\n",
    "    # X = np.matrix(X)\n",
    "    probability = sigmoid(x * theta.T)\n",
    "    prediction = [ 1 if a >= 0.5 else 0 for a in probability]   # prediction结果是一个list\n",
    "    return prediction\n",
    "\n",
    "y_prediction = predict(theta_final,x)\n",
    "correct = [1 if  ((a==1) and (b==1)) or ((a==0)and (b==0)) else 0 for (a,b) in zip(y, y_prediction)]\n",
    "accuracy = (sum(map(int, correct)) % len(correct))\n",
    "print('accuracy = {0}%'.format(accuracy))\n",
    "\n",
    "##############################################################################\n",
    "########--------------------计算 end------------------------########\n",
    "################################################################################\n",
    "\n",
    "'''7。 scikit learn 取代上面自己写的代码'''\n",
    "##############################################################################\n",
    "########--------------------用sikit learn------------------------########\n",
    "################################################################################\n",
    "from sklearn import linear_model\n",
    "\n",
    "model = linear_model.LogisticRegression(penalty='l2', C=1.0)\n",
    "model.fit(x, y.ravel())\n",
    "\n",
    "\n",
    "model.fit(x,y.ravel())\n",
    "model.score(x,y)\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "########--------------------sikit learn------------------------########\n",
    "################################################################################\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
